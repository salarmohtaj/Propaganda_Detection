
@InProceedings{clef-checkthat:2022:LNCS,
	author = {Nakov, Preslav and Barr\'{o}n-Cede\~{n}o, Alberto and Da San Martino, Giovanni and Alam, Firoj and Stru\ss{}, Julia Maria and Mandl, Thomas and M\'{\i}guez, Rub\'{e}n and Caselli, Tommaso and Kutlu, Mucahid and Zaghouani, Wajdi and Li, Chengkai and Shaar, Shaden and Shahi, Gautam Kishore and Mubarak, Hamdy and Nikolov, Alex and Babulkov, Nikolay and Kartal, Yavuz Selim and Beltr\'{a}n, Javier and Wiegand, Michael and Siegel, Melanie and Köhler, Juliane},
	title = "Overview of the {CLEF}-2022 {CheckThat}! Lab on Fighting the {COVID-19} Infodemic and Fake News Detection",
	year = {2022},
	booktitle = "Proceedings of the 13th International Conference of the CLEF Association: Information Access Evaluation meets Multilinguality, Multimodality, and Visualization",
	series = {CLEF~'2022},
	address = {Bologna, Italy},
}

@InProceedings{clef-checkthat:2022:task1,
author = {Nakov, Preslav and Barr\'{o}n-Cede\~{n}o, Alberto and Da San Martino, Giovanni and Alam, Firoj and M\'{\i}guez, Rub\'{e}n and Caselli, Tommaso and Kutlu, Mucahid and Zaghouani, Wajdi and Li, Chengkai and Shaar, Shaden and Mubarak, Hamdy and Nikolov, Alex and Kartal, Yavuz Selim and Beltr\'{a}n, Javier},
title = "Overview of the {CLEF}-2022 {CheckThat}! Lab Task 1 on Identifying Relevant Claims in Tweets",
year = {2022},
booktitle = "Working Notes of CLEF 2022---Conference and Labs of the Evaluation Forum",
series = {CLEF~'2022},
address = {Bologna, Italy},
}



@InProceedings{clef-checkthat:2022:task2,
author = {Nakov, Preslav and Da San Martino, Giovanni and Alam, Firoj and Shaar, Shaden and Mubarak, Hamdy and Babulkov, Nikolay},
title = "Overview of the {CLEF}-2022 {CheckThat}! Lab Task 2 on Detecting Previously Fact-Checked Claims",
year = {2022},
booktitle = "Working Notes of CLEF 2022---Conference and Labs of the Evaluation Forum",
series = {CLEF~'2022},
address = {Bologna, Italy},
}

@InProceedings{CheckThat:ECIR2022,
author="Nakov, Preslav and Barr{\'o}n-Cede{\~{n}}o, Alberto and Da San Martino, Giovanni and Alam, Firoj and Stru{\ss}, Julia Maria and Mandl, Thomas and M{\'i}guez, Rub{\'e}n and Caselli, Tommaso and Kutlu, Mucahid and Zaghouani, Wajdi and Li, Chengkai and Shaar, Shaden and Shahi, Gautam Kishore and Mubarak, Hamdy and Nikolov, Alex and Babulkov, Nikolay and Kartal, Yavuz Selim and Beltr{\'a}n, Javier",
editor="Hagen, Matthias and Verberne, Suzan and Macdonald, Craig and Seifert, Christin and Balog, Krisztian and N{\o}rv{\aa}g, Kjetil and Setty, Vinay",
title="The CLEF-2022 CheckThat! Lab on Fighting the COVID-19 Infodemic and Fake News Detection",
booktitle="Advances in Information Retrieval",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="416--428",
isbn="978-3-030-99739-7"
}


@InProceedings{alam2020call2arms,
	title		= {Fighting the {COVID}-19 Infodemic in Social Media: A
	Holistic Perspective and a Call to Arms},
	author	= {Alam, Firoj and Dalvi, Fahim and Shaar, Shaden and
	Durrani, Nadir and Mubarak, Hamdy and Nikolov, Alex and {Da
	San Martino}, Giovanni and Abdelali, Ahmed and Sajjad,
	Hassan and Darwish, Kareem and Nakov, Preslav},
	year		= {2021},
	pages		= {913-922},
	nomonth	= {May},
	NOvolume	= {15},
	booktitle	= {Proceedings of the International {AAAI} Conference on Web
	and Social Media},
	series	= {ICWSM~'21},
	nourl		= {https://ojs.aaai.org/index.php/ICWSM/article/view/18114}
}

@inproceedings{alam2020fighting,
	title={Fighting the {COVID}-19 Infodemic: Modeling the Perspective of Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the Society},
	author={Firoj Alam and Shaden Shaar and Fahim Dalvi and Hassan Sajjad and Alex Nikolov and Hamdy Mubarak and Giovanni Da San Martino and Ahmed Abdelali and Nadir Durrani and Kareem Darwish and Abdulaziz Al-Homaid and Wajdi Zaghouani and Tommaso Caselli and Gijs Danoe and Friso Stolk and Britt Bruntink and Preslav Nakov},
	booktitle = {Findings of EMNLP 2021},
	pages = {611--649},
	year={2021},
}

@inproceedings{shaar2021findings,
	title={Findings of the {NLP4IF-2021} Shared Tasks on Fighting the {COVID-19} Infodemic and Censorship Detection},
	author={Shaar, Shaden and Alam, Firoj and Da San Martino, Giovanni and Nikolov, Alex and Zaghouani, Wajdi and Nakov, Preslav and Feldman, Anna},
	booktitle={Proceedings of the Fourth Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda},
	pages={82--92},
	series = {NLP4IF~'21},
	year={2021}
}

@inproceedings{nakov-etal-2021-covid,
	title = "{COVID}-19 in {B}ulgarian Social Media: Factuality, Harmfulness, Propaganda, and Framing",
	author = "Nakov, Preslav  and
	Alam, Firoj  and
	Shaar, Shaden  and
	Da San Martino, Giovanni  and
	Zhang, Yifan",
	booktitle = "Proceedings of the International Conference on Recent Advances in Natural Language Processing",
	series = {RANLP~'21},
	NOmonth = sep,
	year = "2021",
	NOaddress = "Held Online",
	NOpublisher = "INCOMA Ltd.",
	NOurl = "https://aclanthology.org/2021.ranlp-main.113",
	pages = "997--1009",
	abstract = "With the emergence of the COVID-19 pandemic, the political and the medical aspects of disinformation merged as the problem got elevated to a whole new level to become the first global infodemic. Fighting this infodemic is currently ranked very high on the list of priorities of the World Health Organization, with dangers ranging from promoting fake cures, rumors, and conspiracy theories to spreading xenophobia and panic. With this in mind, we studied how COVID-19 is discussed in Bulgarian social media in terms of factuality, harmfulness, propaganda, and framing. We found that most Bulgarian tweets contain verifiable factual claims, are factually true, are of potential public interest, are not harmful, and are too trivial to fact-check; moreover, zooming into harmful tweets, we found that they spread not only rumors but also panic. We further analyzed articles shared in Bulgarian partisan pro/con-COVID-19 Facebook groups and found that propaganda is more prevalent in skeptical articles, which use doubt, flag waving, and slogans to convey their message; in contrast, concerned ones appeal to emotions, fear, and authority; moreover, skeptical articles frame the issue as one of quality of life, policy, legality, economy, and politics, while concerned articles focus on health {\&} safety. We release our manually and automatically analyzed datasets to enable further research.",
}

@inproceedings{dimitrov2021semeval2021,
	title={{SemEval}-2021 Task 6: Detection of Persuasion Techniques in Texts and Images}, 
	author={Dimitar Dimitrov and Bishr Bin Ali and Shaden Shaar and Firoj Alam and Fabrizio Silvestri and Hamed Firooz and Preslav Nakov and Giovanni Da San Martino},
	year={2021},
	booktitle={Proceedings of the International Workshop on Semantic Evaluation},
	pages = {70--98},
	series = {SemEval~'21},
}
@Article{claim:retrieval:context:2021,
	author	= {Shaden Shaar and Firoj Alam and Da San Martino, Giovanni
	and Preslav Nakov},
	title		= {The Role of Context in Detecting Previously Fact-Checked
	Claims},
	journal	= {Arxiv:2104.07423},
	year		= {2021}
}

@article{shaar2021assisting,
	title={Assisting the Human Fact-Checkers: Detecting All Previously Fact-Checked Claims in a Document}, 
	author={Shaden Shaar and Firoj Alam and Giovanni Da San Martino and Preslav Nakov},
	year={2021},
	journal={arXiv preprint arXiv:2109.07410},
	eprint={2109.07410},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@InProceedings{survey:2021:ai:fact-checkers,
	author	= {Preslav Nakov and David Corney and Maram Hasanain and
	Firoj Alam and Tamer Elsayed and Alberto
	Barr{\'{o}}n{-}Cede{\~{n}}o and Paolo Papotti and Shaden
	Shaar and Giovanni {Da San Martino}},
	title		= {Automated Fact-Checking for Assisting Human
	Fact-Checkers},
	booktitle	= {Proceedings of the 30th International Joint Conference on
	Artificial Intelligence},
	series	= {IJCAI~'21},
	pages = {4551--4558},
	year		= {2021}
}

@inproceedings{shaar-etal-2020-known,
	title = "That is a Known Lie: Detecting Previously Fact-Checked Claims",
	author = "Shaar, Shaden  and
	Babulkov, Nikolay  and
	Da San Martino, Giovanni  and
	Nakov, Preslav",
	booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
	series = {ACL~'20},
	NOmonth = jul,
	year = "2020",
	NOaddress = "Online",
	NOpublisher = "Association for Computational Linguistics",
	NOurl = "https://www.aclweb.org/anthology/2020.acl-main.332",
	NOdoi = "10.18653/v1/2020.acl-main.332",
	pages = "3607--3618",
}

@inproceedings{nakov2021clef,
  title="The {CLEF-2021 CheckThat!} Lab on Detecting Check-Worthy Claims, Previously Fact-Checked Claims, and Fake News",
  author={Nakov, Preslav and Da San Martino, Giovanni and Elsayed, Tamer and Barr{\'o}n-Cede{\~n}o, Alberto and M{\'\i}guez, Rub{\'e}n and Shaar, Shaden and Alam, Firoj and Haouari, Fatima and Hasanain, Maram and Babulkov, Nikolay and others},
  booktitle={ECIR (2)},
  year={2021}
}

@InProceedings{clef-checkthat:2021:LNCS,
  author    = {Preslav Nakov and
               Da San Martino Giovanni and
               Tamer Elsayed and
               Alberto Barr{\'{o}}n{-}Cede{\~{n}}o and
               Rub\'{e}n M\'{i}guez and
               Shaden Shaar and
               Firoj Alam and
               Fatima Haouari and
               Maram Hasanain and
               Watheq Mansour and
               Bayan Hamdan and
               Zien Sheikh Ali and
               Nikolay Babulkov and
               Alex Nikolov and
               Shahi, Gautam Kishore and
               Struß, Julia Maria and
               Thomas Mandl and
               Mucahid Kutlu and
               Yavuz Selim Kartal},
 title  = "Overview of the {CLEF}-2021 {CheckThat}! Lab on Detecting Check-Worthy Claims, Previously Fact-Checked Claims, and Fake News",
 booktilte = "Experimental {IR} Meets Multilinguality, Multimodality, and Interaction. {P}roceedings of the Twelfth International Conference of the {CLEF} Association",
 Noseries = "{CLEF} 2021",
 editor = "Candan, {K. Selcuk} and 
        Ionescu, Bogdan and
        Goeuriot, Lorraine and
        Larsen, Birger and
        Müller, Henning and
        Joly, Alexis and
        Maistro, Maria and
        Piroi, Florina and 
        Faggioli, Guglielmo and
        Ferro, Nicola",
 year = 2021,
 series    = "LNCS (12880)",
 publisher = "Springer"
}

@dataset{gautam_kishore_shahi_2021_4714517,
  author       = {Gautam Kishore Shahi and
                  Julia Maria Struß and
                  Thomas Mandl},
  title        = {{CT-FAN-21 corpus: A dataset for Fake News 
                   Detection}},
  month        = apr,
  year         = 2021,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.4714517},
  url          = {https://doi.org/10.5281/zenodo.4714517}
}


@InProceedings{clef-checkthat:2021:task1,
  author    = {Shaden Shaar and
               Maram Hasanain and
               Bayan Hamdan and
               Zien Sheikh Ali and
               Fatima Haouari and
               Alex Nikolov and
               Mucahid Kutlu and
               Yavuz Selim Kartal and
               Firoj Alam and
               Da San Martino, Giovanni and
               Alberto Barr{\'{o}}n{-}Cede{\~{n}}o and
               Rub\'{e}n M\'{i}guez and
               Javier Beltr\'an and
               Tamer Elsayed and
               Preslav Nakov},
 title  = "Overview of the {CLEF}-2021 {CheckThat}! Lab Task 1 on Check-Worthiness Estimation in Tweets and Political Debates",
 year = {2021}, 
 crossref = "clef2021-workingnotes"
}

@inproceedings{DBLP:conf/ecir/NakovMEBMSAHHBN21,
  author    = {Preslav Nakov and
               Giovanni Da San Martino and
               Tamer Elsayed and
               Alberto Barr{\'{o}}n{-}Cede{\~{n}}o and
               Rub{\'{e}}n M{\'{\i}}guez and
               Shaden Shaar and
               Firoj Alam and
               Fatima Haouari and
               Maram Hasanain and
               Nikolay Babulkov and
               Alex Nikolov and
               Gautam Kishore Shahi and
               Julia Maria Stru{\ss} and
               Thomas Mandl},
  editor    = {Djoerd Hiemstra and
               Marie{-}Francine Moens and
               Josiane Mothe and
               Raffaele Perego and
               Martin Potthast and
               Fabrizio Sebastiani},
  title     = {The {CLEF-2021} CheckThat! Lab on Detecting Check-Worthy Claims, Previously
               Fact-Checked Claims, and Fake News},
  booktitle = {Advances in Information Retrieval - 43rd European Conference on {IR}
               Research, {ECIR} 2021, Virtual Event, March 28 - April 1, 2021, Proceedings,
               Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {12657},
  pages     = {639--649},
  publisher = {Springer},
  year      = {2021},
  url       = {https://doi.org/10.1007/978-3-030-72240-1\_75},
  doi       = {10.1007/978-3-030-72240-1\_75},
  timestamp = {Tue, 30 Mar 2021 18:55:01 +0200},
  biburl    = {https://dblp.org/rec/conf/ecir/NakovMEBMSAHHBN21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{clef-checkthat:2021:task3:UnivRegensburg,
  author    = {  Hartl , Philipp and  Kruschwitz,  Udo},
 title  = "University of {Regensburg} at {CheckThat!} 2021: Exploring Text Summarization for Fake NewsDetection",
 crossref = "clef2021-workingnotes"
}	

@InProceedings{clef-checkthat:2021:task3:Tsoplefack,
  author    = {Tsoplefack	, William Kana  },
 title  = "Classifier for fake news detection and Topical Domain of News Articles",
 crossref = "clef2021-workingnotes"
}	

@InProceedings{clef-checkthat:2021:task1:Schlicht2021,
  author    = "{Baris Schlicht}, Ipek and
                {Magnossão de Paula}, {Angel Felipe} and
                 Rosso, Paolo",
 title  = "{UPV} at {CheckThat! 2021}: Mitigating Cultural Differences for Identifying Multilingual Check-worthy Claims ",
 crossref = "clef2021-workingnotes"
}



@InProceedings{clef-checkthat:2021:task1:accenture,
  author    = {Williams, Evan  and
                Rodrigues, Paul and Tran, Sieu },
 title  = "Accenture at {CheckThat!} 2021: Interesting claim identification and ranking with contextually sensitive lexical training data augmentation",
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task3:MUCIC,
author    = {Balouchzahi, Fazlourrahman and Shashirekha, { H. L. } and Sidorov , Grigori },
 title  = "{MUCIC at CheckThat!} 2021: {FaDo}-Fake News Detection and Domain Identification using Transformers Ensembling",
 pages = {455--464},
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task3:Ashraf,
author    = {Ashraf, Noman and Butt, Sabur and Sidorov, Grigori and Gelbukh, Alexander},
 title  = "Fake News Detection Using Machine Learning And Data Augmentation -- {CLEF2021}",
 crossref = "clef2021-workingnotes"
}


@InProceedings{clef-checkthat:2021:task3:Kovachevich,
  author    = {Kovachevich, Ninko },
 title  = "{BERT} fine-tuning approach to {CLEF CheckThat!} fake news detection",
 crossref = "clef2021-workingnotes"
}	

%conditional accept: will only be cited in task overview, since deadline of re-submission is the same as for this paper
%TODO: remove citation from tables and text, DONE
@InProceedings{clef-checkthat:2021:task3:Kumari,
  author    = {Kumari, Sushma },
 title  = "{NoFake} at {CheckThat!} 2021: Fake news detection using {BERT}",
 crossref = "clef2021-workingnotes"
}	

%conditional accept: will only be cited in task overview, since deadline of re-submission is the same as for this paper
%TODO: remove citation from tables and text
@InProceedings{clef-checkthat:2021:task1:Sepulveda2021,
  author    = "Sep\'ulveda-Torres, Robiert  and
                Saquete, Estela",
 title  = "{GPLSI} team at {CLEF CheckThat! 2021}: Fine-tuning {BETO} and {RoBERTa}",
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task1:Zhou2021,
  author    = "Zhou, Xinrui and 
                Wu, Bohuai and 
                Fung, Pascale",
 title  = "{Fight for 4230} at {CLEF CheckThat! 2021}: Domain-Specific Preprocessing and Pretrained Model for Ranking Claims by Check-Worthiness",
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task1:tobbetu,
  author    = "Zengin, Muhammed Said and 
                Kartal, Yavuz Selim and 
                Kutlu, Mucahid",
 title  = "{TOBB ETU} at {CheckThat! 2021}: Data Engineering for Detecting Check-Worthy Claims",
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task1:sunlp,
  author    = "Carik, Buse and 
                Yeniterzi, Reyyan",
 title  = "{SU-NLP} at {CheckThat! 2021}: Check-Worthiness of {T}urkish Tweets",
 crossref = "clef2021-workingnotes"
}

%conditional accept: will only be cited in task overview, since deadline of re-submission is the same as for this paper
%TODO: remove citation from tables and text, DONE
@InProceedings{clef-checkthat:2021:task3:spider,
  author    = { Zumma, Md Thoufiq and Islam, Md. Sanzidul Hasan and Md. Arid Khushbu and Sharun Akter},
 title  = "Spider at {CheckThat! 2021}: Fake News Detection False to True Identification Using Deep Learning",
 crossref = "clef2021-workingnotes"
}


@InProceedings{clef-checkthat:2021:task2,
  author    = {Shaden Shaar and
               Fatima Haouari and
               Watheq Mansour and 
               Maram Hasanain and
               Nikolay Babulkov and
               Firoj Alam and
               Da San Martino, Giovanni and
               Tamer Elsayed and
               Preslav Nakov},
 title  = "Overview of the {CLEF}-2021 {CheckThat}! Lab Task 2 on Detecting Previously Fact-Checked Claims in Tweets and Political Debates",
 crossref = "clef2021-workingnotes"
}


@InProceedings{clef-checkthat:2021:task3,
  author    = {Shahi, Gautam Kishore and
               Struß, Julia Maria and
               Thomas Mandl},
 title  = "Overview of the {CLEF}-2021 {CheckThat}! Lab: Task 3 on Fake News Detection",
 year = {2021}, 
 crossref = "clef2021-workingnotes"
}

%conditional accept: will only be cited in task overview, since deadline of re-submission is the same as for this paper
%TODO: remove citation from tables and text; DONE
@InProceedings{clef-checkthat:2021:task3:saud2021,
  author    = {Althabiti, Saud and
               Alsalka, Mohammad  and
               Atwell, Eric},
 title  = "Detecting Fake News Using {SVC} with {TF-IDF}",
 year = {2021}, 
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task3:Chernyavskiy2021,
  author    = {Chernyavskiy, Anton and Ilvovsky, Dmitry and  Nakov, Preslav},
 title  = "Aschern at {CLEF CheckThat!} 2021: Lambda-Calculus of Fact-Checked Claims",
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task1:S.Abumansour2021,
  author    = {Abumansour, Amani and  Zubiaga, Arkaitz},
 title  = "{QMUL-SDS} at {CheckThat!} 2021: Enriching Pre-Trained Language Models for the Estimation of Check-Worthiness of {A}rabic Tweets",
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task1:althabiti2021,
  author    = {Althabiti, Saud and  Alsalka, Mohammad and Atwell, Eric},
 title  = "An {AraBERT} Model for Check-Worthiness of {A}rabic Tweets",
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task2:beasku2021,
  author    = {Skuczyńska, Beata  and Shaar, Shaden and Spenader, Jennifer  and Nakov, Preslav},
 title  = "{BeaSku} at {CheckThat!} 2021: Fine–Tuning Sentence {BERT} with Triplet Loss and Limited Data",
 crossref = "clef2021-workingnotes"
}

%conditional accept: will only be cited in task overview, since deadline of re-submission is the same as for this paper
%TODO: remove citation from tables and text; DONE
@InProceedings{clef-checkthat:2021:task3:Majumdar2021,
  author    = {Majumdar, Bhaskar and Bhuiyan, Md. Rafiuzzaman and  Hasan, Md. Arid and Islam, Md. Sanzidul and Haider Noori, Sheak Rashed},
 title  = "Probity at {CheckThat!} 2021: Multi Class Fake News Detection Using {LSTM} Approach",
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task3:Martinez-Rico,
  author    = {Juan R. Martinez-Rico, Juan Martinez-Romo and Lourdes Araujo},
 title  = "{NLP\&IR@UNED} at {CheckThat!} 2021: Check-worthiness estimation and fake news detection using transformer models",
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task3:UAICS,
  author    = {Cusmuliuc, Ciprian-Gabriel and
                Amarandei, Matei-Alexandru and
                Pelin, Ioana and 
                Cociorva, Vlad-Iulian and
                Iftene, Adrian},
 title  = "{UAICS} at {CheckThat!} 2021: Fake news detection",
 crossref = "clef2021-workingnotes"
}


@proceedings{clef2021-workingnotes,
 editor = "Faggioli, Guglielmo and 
        Ferro, Nicola and 
        Joly, Alexis and 
        Maistro, Maria and
        Piroi, Florina",
    title = "{CLEF} 2021 Working Notes. {W}orking Notes of {CLEF} 2021--Conference and Labs of the Evaluation Forum",
    NOpublisher = "CEUR-WS.org",
    Noaddress = {Bucharest, Romania (online)},
    year = 2021,
}
% issn= "1613-0073",

%conditional accept: will only be cited in task overview, since deadline of re-submission is the same as for this paper
%TODO: remove citation from tables and text
@InProceedings{clef-checkthat:2021:task1:nlytics2021,
  author    = {Pritzkau, Albert},
 title  = "{NLytics} at {CheckThat!} 2021: Check-Worthiness Estimation as a Regression Problem on Transformers",
 crossref = "clef2021-workingnotes"
}

%conditional accept: will only be cited in task overview, since deadline of re-submission is the same as for this paper
%TODO: remove citation from tables and text
@InProceedings{clef-checkthat:2021:task2:nlytics2021,
  author    = {Pritzkau, Albert},
 title  = "{NLytics} at {CheckThat!} 2021: Detecting Previously Fact-Checked Claims by Measuring Semantic Similarity",
 crossref = "clef2021-workingnotes"
}

%conditional accept: will only be cited in task overview, since deadline of re-submission is the same as for this paper
%TODO: remove citation from tables and text; DONE
@InProceedings{clef-checkthat:2021:task3:nlytics2021,
  author    = {Pritzkau, Albert},
 title  = "{NLytics} at {CheckThat!} 2021: Multi-class fake news detection of news articles and domain identification with {RoBERTa} - a baseline model",
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task3:blackops2021,
  author    = {Sohan, S.M. and 
               Rajon, Hemaddry Sarker and
               Khusbu, Akter and 
               Islam, Md. Sanzidul and 
               Hasan, Md. Arid},
 title  = "{Black Ops} at {CheckThat!} 2021: User Profiles Analyze of Intelligent Detection on Fake Tweets Notebook in Shared Task",
 crossref = "clef2021-workingnotes"
}


@InProceedings{clef-checkthat:2021:task3:Hariharan,
  author    = {{L} , Hariharan R  and  M	, {Anand Kumar}},
 title  = "{NITK\_NLP} at {CLEF} {CheckThat!} 2021: Ensemble Transformer Model for Fake News Classification",
 crossref = "clef2021-workingnotes"
}


@InProceedings{clef-checkthat:2021:task3:civicupm2021,
  author    = {\'{A}lvaro Huertas-Garc\i{i}a and Javier Huertas-Tato and Alejandro Mart\'{i}n and David Camacho},
 title  = "{CIVIC-UPM at CheckThat! 2021}: Integration of Transformers in Misinformation detection and Topic classification",
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task1:qmulsds,
  author    = "Amani Abumansour and Arkaitz Zubiaga",
 title  = "{QMUL-SDS at CheckThat! 2021}: Enriching Pre-Trained Language Models for the Estimation of Check-Worthiness of {A}rabic Tweets",
 crossref = "clef2021-workingnotes"
}

%conditional accept: will only be cited in task overview, since deadline of re-submission is the same as for this paper
%TODO: remove citation from tables and text; DONE
@InProceedings{clef-checkthat:2021:task3:KannanDLRG,
  author    = {R.Ramesh Kannan and Rajalakshmi R },
 title  = "{DLRG@CLEF2021}: An Ensemble approach for Fake Detection on News articles",
 crossref = "clef2021-workingnotes"
}	

%conditional accept: will only be cited in task overview, since deadline of re-submission is the same as for this paper
%TODO: remove citation from tables and text
@InProceedings{clef-checkthat:2021:task1:iCompass,
  author    = "Oumayma Rjab and Hatem Haddad and Wassim Henia and Chayma Fourati",
 title  = "{iCompass at CheckThat!} 2021: Identifying Check-Worthy {A}rabic Tweets",
 crossref = "clef2021-workingnotes"
}


@InProceedings{clef-checkthat:2021:task2:DIPS,
  author = {Mihaylova, Simona and Borisova, Iva and Chemishanov, Dzhovani and Hadzhitsanev, Preslav and Hardalov, Momchil and Nakov, Preslav},
 title  = "{DIPS at CheckThat!} 2021: Verified Claim Retrieval",
 crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task3:sigmoid,
    author = {Abdullah Al Mamun Sardar and Shahalu Akter Salma and  Md. Sanzidul Islam and  Md. Arid Hasan and Touhid Bhuiyan},
    title = "Team {Sigmoid at CheckThat!} 2021: Multiclass fake news detection with Machine Learning",
    crossref = "clef2021-workingnotes",
}

@InProceedings{clef-checkthat:2021:task3:ashik,
    author = {Sohel Siddique Ashik and Abdur Rahman Apu and  Nushrat Jahan Marjana and Md. Arid Hasan and Md. Sanzidul Islam},
    title = "{M82B} at {CheckThat!} 2021: Multiclass fake news detection using {BiLSTM} based {RNN} model",
    crossref = "clef2021-workingnotes"
}

@InProceedings{clef-checkthat:2021:task3:qword,
    author = {Rudra Sarker Utsha and Mumenunnessa Keya and  Md. Arid Hasan and  Md. Sanzidul Islam},
    title = "{Qword} at {CheckThat!} 2021: An Extreme Gradient Boosting Approach for Multiclass Fake News Detection",
    crossref = "clef2021-workingnotes"
}

@article{shahi2021,
  title={A multilingual domain identification using fact-checked articles: A case study on COVID-19 misinformation},
  author={Shahi, Gautam Kishore},
  journal={arXiv preprint},
  year={2021}
}

@article{shahi_2021,
  title={Exploring the Spread of {COVID-19} Misinformation on {T}witter},
  author={Shahi, Gautam Kishore and Anne Dirkson and Majchrzak, Tim A.},
  journal={arXiv preprint},
  year={2021}
}


@article{shahi2021exploratory,
  title={An exploratory study of {COVID}-19 misinformation on {T}witter},
  author={Shahi, Gautam Kishore and Dirkson, Anne and Majchrzak, Tim A},
  journal={Online social networks and media},
  volume={22},
  pages={100104},
  year={2021},
  publisher={Elsevier}
}

@article{shahi2020fakecovid,
  title={FakeCovid--A multilingual cross-domain fact check news dataset for COVID-19},
  author={Shahi, Gautam Kishore and Nandini, Durgesh},
  journal={arXiv preprint arXiv:2006.11343},
  year={2020}
}

@article{kazemi2021tiplines,
  title={Tiplines to Combat Misinformation on Encrypted Platforms: A Case Study of the 2019 Indian Election on WhatsApp},
  author={Kazemi, Ashkan and Garimella, Kiran and Shahi, Gautam Kishore and Gaffney, Devin and Hale, Scott A},
  journal={arXiv preprint arXiv:2106.04726},
  year={2021}
}

@InProceedings{CheckThat:ECIR:2021,
author="Nakov, Preslav
and Da San Martino, Giovanni
and Elsayed, Tamer
and Barr{\'o}n-Cede{\~{n}}o, Alberto
and M{\'i}guez, Rub{\'e}n
and Shaar, Shaden
and Alam, Firoj
and Haouari, Fatima
and Hasanain, Maram
and Babulkov, Nikolay
and Nikolov, Alex
and Shahi, Gautam Kishore
and Stru{\ss}, Julia Maria
and Mandl, Thomas",
title="The {CLEF-2021 CheckThat!} Lab on Detecting Check-Worthy Claims, Previously Fact-Checked Claims, and Fake News",
booktitle="Advances in  Information Retrieval",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="639--649",
abstract="We describe the fourth edition of the CheckThat! Lab, part of the 2021 Cross-Language Evaluation Forum (CLEF). The lab evaluates technology supporting various tasks related to factuality, and it is offered in Arabic, Bulgarian, English, and Spanish. Task 1 asks to predict which tweets in a Twitter stream are worth fact-checking (focusing on COVID-19). Task 2 asks to determine whether a claim in a tweet can be verified using a set of previously fact-checked claims. Task 3 asks to predict the veracity of a target news article and its topical domain. The evaluation is carried out using mean average precision or precision at rank k for the ranking tasks, and F{\$}{\$}{\_}1{\$}{\$}1for the classification tasks.",
isbn="978-3-030-72240-1"
}


@InProceedings{clef-checkthat-T1:2018,
 author = "Atanasova, Pepa and
    Marquez, Lluis and
    Barr\'{o}n-Cede{\~n}o, Alberto and
    Elsayed, Tamer and
    Suwaileh, Reem and 
    Zaghouani, Wajdi and 
    Kyuchukov, Spas and
    Da San Martino, Giovanni and
    Nakov, Preslav",
 title = "Overview of the {CLEF-2018 CheckThat!} Lab on Automatic Identification and Verification of Political Claims. {T}ask 1: Check-Worthiness",
 crossref = "clef2018-workingnotes"
}

@InProceedings{clef-checkthat-T2:2018,
 author = "Barr\'{o}n-Cede{\~n}o, Alberto and
    Elsayed, Tamer and
    Suwaileh, Reem and 
    Marquez, Lluis and
    Atanasova, Pepa and
    Zaghouani, Wajdi and 
    Kyuchukov, Spas and        
    Da San Martino, Giovanni and
    Nakov, Preslav",
 title = "Overview of the {CLEF-2018 CheckThat!} Lab on Automatic Identification and Verification of Political Claims. {T}ask 2: Factuality",
 crossref = "clef2018-workingnotes"
}


@InProceedings{T1-Agez:2018,
 author = "Agez, Romain and 
	  Bosc, Clement and 
	  Lespagnol, Cedric and
	  Mothe, Josiane and 
	  Petitcol, Noemie",
 title = "{IRIT at CheckThat! 2018}",
 crossref = "clef2018-workingnotes"
}

@InProceedings{T1-Ghanem:2018,
 author = "Ghanem, Bilal and 
	  Montes-y-G\'{o}mez, Manuel and
	   Rangel, Francisco and 
	   Rosso, Paolo",
 title = "{UPV-INAOE-Autoritas - Check That}: Preliminary Approach for Checking Worthiness of Claims",
 crossref = "clef2018-workingnotes"
}

@InProceedings{T1-Hansen:2018,
 author = "Hansen, Casper and 
	Hansen, Christian and
	Simonsen, {Jakob Grue} and 
	Lioma, Christina",
 title = "The {C}openhagen Team Participation in the Check-Worthiness Task of the Competition of Automatic Identification and Verification of Claims in Political Debates of the {CLEF-2018} Fact Checking Lab",
 crossref = "clef2018-workingnotes"
}

@InProceedings{clef2018checkthat,
 author = "Nakov, Preslav and 
	Barr\'{o}n-Cede{\~n}o, Alberto and 
	Elsayed, Tamer and 
	Suwaileh, Reem and 
	M\`{a}rquez, Llu\'{i}s and 
	Zaghouani, Wajdi and 
	Gencheva, Pepa and 
	Kyuchukov, Spas and 
	{Da San Martino}, Giovanni",
 title  = "Overview of the {CLEF}-2018 Lab on Automatic Identification and Verification of Claims in Political Debates",
 booktitle = "Working Notes of {CLEF} 2018 -- Conference and Labs of the Evaluation Forum",
 series    = {CLEF~'18},
 NOmonth     = {September},
 year      = 2018 
}


@InProceedings{T1-Zuo:2018,
 author = "Zuo, Chaoyuan and 
	Karakas, Ayla and
	Banerjee, Ritwik",
 title = "A Hybrid Recognition System for Check-worthy Claims Using Heuristics and Supervised Learning",
 crossref = "clef2018-workingnotes"
}

@proceedings{clef2018-workingnotes,
 editor = "Cappellato, Linda  and
 	Ferro, Nicola and
 	Nie, Jian-Yun and
 	Soulier, Laure",
 title = "Working Notes of CLEF 2018--Conference and Labs of the Evaluation Forum",
 series    = "{CEUR} Workshop Proceedings",
    NOpublisher = "CEUR-WS.org",
 year = 2018
}
@InProceedings{clef-checkthat:2019,
 author = "Elsayed, Tamer and
    Nakov, Preslav and
    Barr\'{o}n-Cede{\~n}o, Alberto and
    Hasanain, Maram and
    Suwaileh, Reem and
    {Da San Martino}, Giovanni and 
    Atanasova, Pepa",
 title  = "{Overview of the CLEF-2019 CheckThat!}: Automatic Identification and Verification of Claims",
 booktitle = "Experimental IR Meets Multilinguality, Multimodality, and Interaction",
 series    = "LNCS",
 pages="301--321",
 NOpublisher = "Springer",
 year = 2019
}

@InProceedings{clef-checkthat-T1:2019,
    author = "Atanasova, Pepa and
    Nakov, Preslav and
    Karadzhov, Georgi and
    Mohtarami, Mitra and
    Da San Martino, Giovanni",
    title  = "{Overview of the CLEF-2019 CheckThat!} Lab on Automatic Identification and Verification of Claims. {T}ask 1: Check-Worthiness",
    crossref = "ClefCeur:2019"
}

@InProceedings{clef-checkthat-T2:2019,
    author = "Hasanain, Maram and
    Suwaileh, Reem and
    Elsayed, Tamer and
    Barr\'{o}n-Cede{\~n}o, Alberto and
    Nakov, Preslav",
    title  = "{Overview of the CLEF-2019 CheckThat!} Lab on Automatic Identification and Verification of Claims. {T}ask 2: Evidence and Factuality",
    crossref = "ClefCeur:2019"
}

@InProceedings{T1-Altun:2019,
    author    = "Altun, Bahadir and
                Kutlu, Mucahid",
    title     = "{TOBB-ETU at CLEF 2019:} Prioritizing Claims Based on Check-Worthiness",
    crossref = "ClefCeur:2019"
}

@InProceedings{T1-Coca:2019,
    author   = "Coca, {Lucia Georgiana} and
            Cusmuliuc, Ciprian-Gabriel and
            Iftene, Adrian",
    title    = "{CheckThat! 2019 UAICS}",
    crossref = "ClefCeur:2019"
}

@InProceedings{T1-Dhar:2019,
    author    = "Dhar, Rudra and
                Dutta, Subhabrata and
                Das, Dipankar",
    title     = "A Hybrid Model to Rank Sentences for Check-worthiness",
    crossref = "ClefCeur:2019"
}

@InProceedings{T1-T2-Favano:2019,
    author    = "Favano, Luca and
                Carman, {Mark J.} and
                Lanzi, {Pier Luca}",
    title     = "{TheEarthIsFlat}'s Submission to {CLEF’19 CheckThat! Challenge}",
    crossref = "ClefCeur:2019"
}


@InProceedings{T1-Gasior:2019,
    author    = "Gasior, Jakub and
                Przyby{\l}a, Piotr ",
    title     = "The {IPIPAN} Team Participation in the Check-Worthiness Task of the {CLEF2019 CheckThat! Lab}",
    crossref = "ClefCeur:2019"
}

@InProceedings{T1-Hansen:2019,
    author    = "Hansen, Casper and
            Hansen, Christian and
            Simonsen, {Jakob Grue} and
            Lioma, Christina",
    title     = "Neural Weakly Supervised Fact Check-Worthiness Detection with Contrastive Sampling-Based Ranking Loss",
    crossref = "ClefCeur:2019"
}

@InProceedings{T1-Mohtaj:2019,
    author    = "Mohtaj, Salar and
                Himmelsbach, Tilo and
                Woloszyn, Vinicius and
                Möller, Sebastian",
    title     = "The {TU-Berlin} Team Participation in the Check-Worthiness Task of the {CLEF-2019 CheckThat! Lab}",
    crossref = "ClefCeur:2019"
}

@InProceedings{T1-Su:2019,
    author    = "Su, Ting and
                Macdonald, Craig and
                Ounis, Iadh",
    title     = "Entity Detection for Check-worthiness Prediction: {Glasgow Terrier at CLEF CheckThat! 2019}",
    crossref = "ClefCeur:2019"
}

@InProceedings{T2-Ghanem:2019,
    author    = "Ghanem, Bilal and
                Glavaš, Goran and
                Giachanou, Anastasia and
                Ponzetto, {Simone Paolo} and
                Rosso, Paolo and
                Rangel, Francisco",
    title     = "{UPV-UMA at CheckThat!} Lab: Verifying {A}rabic Claims using Cross Lingual Approach",
    crossref = "ClefCeur:2019"
}

@InProceedings{T2Haouari:2019,
    author    = "Haouari, Fatima and
                Ali, {Zien Sheikh} and
                Elsayed, Tamer",
    title     = "{bigIR at CLEF 2019}: Automatic Verification of {A}rabic Claims over the Web",
    crossref = "ClefCeur:2019"
}

@InProceedings{T2-Touahri:2019,
    author    = "Touahri, Ibtissam and
                Mazroui, Azzeddine ",
    title     = "Automatic Identification and Verification of Political Claims",
    crossref = "ClefCeur:2019"
}

@proceedings{ClefCeur:2019,
    editor = "Cappellato, Linda and
        Ferro, Nicola and
        Losada, {David E.} and
        M{\"u}ller, Henning",
    title = "Working Notes of {CLEF} 2019 Conference and Labs of the Evaluation Forum",
    series    = "{CEUR} Workshop Proceedings",
    NOpublisher = "CEUR-WS.org",
    year      = "2019"
}

@InProceedings{CheckThat:ECIR:2019,
author="Elsayed, Tamer
and Nakov, Preslav
and Barr{\'o}n-Cede{\~{n}}o, Alberto
and Hasanain, Maram
and Suwaileh, Reem
and Da San Martino, Giovanni
and Atanasova, Pepa",
editor="Azzopardi, Leif
and Stein, Benno
and Fuhr, Norbert
and Mayr, Philipp
and Hauff, Claudia
and Hiemstra, Djoerd",
title="{CheckThat! at CLEF 2019}: Automatic Identification and Verification of Claims",
booktitle="Advances in Information Retrieval",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="309--315",
abstract="We introduce the second edition of the CheckThat! Lab, part of the 2019 Cross-Language Evaluation Forum (CLEF). CheckThat! proposes two complementary tasks. Task 1: predict which claims in a political debate should be prioritized for fact-checking. Task 2: rank Web-retrieved pages against a check-worthy claim based on their usefulness for fact-checking, extract useful passages from those pages, and then use them all to decide whether the claim is factually true or false. Checkthat! provides a full evaluation framework, consisting of data in English (derived from fact-checking sources) and Arabic (gathered and annotated from scratch) and evaluation based on mean average precision (MAP) for ranking and F{\$}{\$}{\_}1{\$}{\$}1for classification tasks.",
isbn="978-3-030-15719-7"
}
@inproceedings{pogorelov2020fakenews,
  title={{FakeNews}: Corona Virus and {5G} Conspiracy Task at {MediaEval} 2020},
  author={Pogorelov, Konstantin and Schroeder, Daniel Thilo and Burchard, Luk and Moe, Johannes and Brenner, Stefan and Filkukova, Petra and Langguth, Johannes},
  booktitle={Proceedings of the MediaEval 2020 Workshop},
  series = {MediaEval~'20},
  year={2020}
}
@article{thorne2018fever,
  title={FEVER: a large-scale dataset for fact extraction and verification},
  author={Thorne, James and Vlachos, Andreas and Christodoulopoulos, Christos and Mittal, Arpit},
  journal={arXiv preprint arXiv:1803.05355},
  year={2018}
}
@inproceedings{thorne-etal-2018-fever,
    title = "{FEVER}: a Large-scale Dataset for Fact Extraction and {VER}ification",
    author = "Thorne, James  and
      Vlachos, Andreas  and
      Christodoulopoulos, Christos  and
      Mittal, Arpit",
    booktitle = "Proceedings of the Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    year = "2018",
	series = {NAACL~'18},
    pages = "809--819",
}
@inproceedings{da2020semeval,
  title={{SemEval}-2020 task 11: Detection of propaganda techniques in news articles},
  author={Da San Martino, Giovanni and Barr{\'o}n-Cedeno, Alberto and Wachsmuth, Henning and Petrov, Rostislav and Nakov, Preslav},
  booktitle={Proceedings of the 14th Workshop on Semantic Evaluation},
  series = {SemEval~'20},
  pages={1377--1414},
  year={2020}
}
@article{zampieri2019semeval,
title = "{S}em{E}val-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media ({O}ffens{E}val)",
    author = "Zampieri, Marcos  and
      Malmasi, Shervin  and
      Nakov, Preslav  and
      Rosenthal, Sara  and
      Farra, Noura  and
      Kumar, Ritesh",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    series = {SemEval~'19},
    NOmonth = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    NOpublisher = "Association for Computational Linguistics",
    NOurl = "https://www.aclweb.org/anthology/S19-2010",
    NOdoi = "10.18653/v1/S19-2010",
    pages = "75--86",
    abstract = "We present the results and the main findings of SemEval-2019 Task 6 on Identifying and Categorizing Offensive Language in Social Media (OffensEval). The task was based on a new dataset, the Offensive Language Identification Dataset (OLID), which contains over 14,000 English tweets, and it featured three sub-tasks. In sub-task A, systems were asked to discriminate between offensive and non-offensive posts. In sub-task B, systems had to identify the type of offensive content in the post. Finally, in sub-task C, systems had to detect the target of the offensive posts. OffensEval attracted a large number of participants and it was one of the most popular tasks in SemEval-2019. In total, nearly 800 teams signed up to participate in the task and 115 of them submitted results, which are presented and analyzed in this report.",
}

@article{zampieri2020semeval,
  title={Semeval-2020 task 12: Multilingual offensive language identification in social media (offenseval 2020)},
  author={Zampieri, Marcos and Nakov, Preslav and Rosenthal, Sara and Atanasova, Pepa and Karadzhov, Georgi and Mubarak, Hamdy and Derczynski, Leon and Pitenis, Zeses and {\c{C}}{\"o}ltekin, {\c{C}}a{\u{g}}r{\i}},
  journal={arXiv preprint arXiv:2006.07235},
  year={2020}
}

@inproceedings{mohammad2016semeval,
  title={{SemEval}-2016 task 6: Detecting stance in tweets},
  author={Mohammad, Saif and Kiritchenko, Svetlana and Sobhani, Parinaz and Zhu, Xiaodan and Cherry, Colin},
  booktitle={Proceedings of the 10th International Workshop on Semantic Evaluation},
  pages={31--41},
  series = {SemEval~'16},
  year={2016}
}

@inproceedings{mihaylova2019semeval,
    title = "{S}em{E}val-2019 Task 8: Fact Checking in Community Question Answering Forums",
    author = "Mihaylova, Tsvetomila  and
      Karadzhov, Georgi  and
      Atanasova, Pepa  and
      Baly, Ramy  and
      Mohtarami, Mitra  and
      Nakov, Preslav",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    series = {SemEval~'19},
    NOmonth = jun,
    year = "2019",
    NOaddress = "Minneapolis, Minnesota, USA",
    NOpublisher = "Association for Computational Linguistics",
    NOurl = "https://www.aclweb.org/anthology/S19-2149",
    NOdoi = "10.18653/v1/S19-2149",
    pages = "860--869",
    abstract = "We present SemEval-2019 Task 8 on Fact Checking in Community Question Answering Forums, which features two subtasks. Subtask A is about deciding whether a question asks for factual information vs. an opinion/advice vs. just socializing. Subtask B asks to predict whether an answer to a factual question is true, false or not a proper answer. We received 17 official submissions for subtask A and 11 official submissions for Subtask B. For subtask A, all systems improved over the majority class baseline. For Subtask B, all systems were below a majority class baseline, but several systems were very close to it. The leaderboard and the data from the competition can be found at http://competitions.codalab.org/competitions/20022.",
}

@inproceedings{mihaylova-etal-2019-semeval,
    title = "{S}em{E}val-2019 Task 8: Fact Checking in Community Question Answering Forums",
    author = "Mihaylova, Tsvetomila  and
      Karadzhov, Georgi  and
      Atanasova, Pepa  and
      Baly, Ramy  and
      Mohtarami, Mitra  and
      Nakov, Preslav",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    year = "2019",
    pages = "860--869",
    series = {SemEval~'19},
}

@inproceedings{gorrell2019semeval,
  title={{SemEval}-2019 task 7: {RumourEval}, determining rumour veracity and support for rumours},
  author={Gorrell, Genevieve and Kochkina, Elena and Liakata, Maria and Aker, Ahmet and Zubiaga, Arkaitz and Bontcheva, Kalina and Derczynski, Leon},
  booktitle={Proceedings of the 13th International Workshop on Semantic Evaluation},
  series = {SemEval~'19},
  pages={845--854},
  year={2019}
}

@inproceedings{derczynski2017semeval,
    title = "{S}em{E}val-2017 Task 8: {R}umour{E}val: Determining rumour veracity and support for rumours",
    author = "Derczynski, Leon  and
      Bontcheva, Kalina  and
      Liakata, Maria  and
      Procter, Rob  and
      Wong Sak Hoi, Geraldine  and
      Zubiaga, Arkaitz",
    booktitle = "Proceedings of the 11th International Workshop on Semantic Evaluation",
    series = {SemEval~'17},
    NOmonth = aug,
    year = "2017",
    NOaddress = "Vancouver, Canada",
    NOpublisher = "Association for Computational Linguistics",
    NOurl = "https://www.aclweb.org/anthology/S17-2006",
    NOdoi = "10.18653/v1/S17-2006",
    pages = "69--76",
    abstract = "Media is full of false claims. Even Oxford Dictionaries named {``}post-truth{''} as the word of 2016. This makes it more important than ever to build systems that can identify the veracity of a story, and the nature of the discourse around it. RumourEval is a SemEval shared task that aims to identify and handle rumours and reactions to them, in text. We present an annotation scheme, a large dataset covering multiple topics {--} each having their own families of claims and replies {--} and use these to pose two concrete challenges as well as the results achieved by participants on these challenges.",
}

@InProceedings{clef-checkthat-lncs:2020,
 author = "Barr\'{o}n-Cede{\~n}o, Alberto and
    Elsayed, Tamer and
    Nakov, Preslav and
    {Da San Martino}, Giovanni and 
    Hasanain, Maram and    
    Suwaileh, Reem and
    Haouari, Fatima and
    Babulkov, Nikolay and
    Hamdan, Bayan and 
    Nikolov, Alex and    
    Shaar, Shaden and
    {Sheikh Ali}, Zien",
 title  = "{Overview of CheckThat! 2020}: Automatic Identification and
Verification of Claims in Social Media",
 pages="215--236",
 crossref = "CLEF_LNCS:20",
}


@InProceedings{clef-checkthat-ar:2020,
 author = "Hasanain, Maram and    
    Haouari, Fatima and
    Suwaileh, Reem and
    Ali, {Zien Sheikh} and
    Hamdan, Bayan and 
    Elsayed, Tamer and
    Barr\'{o}n-Cede{\~n}o, Alberto and
    {Da San Martino}, Giovanni and
    Nakov, Preslav",
 title = "Overview of {CheckThat!} 2020 {A}rabic: Automatic Identification and Verification of Claims in Social Media",
 crossref = "clef2020-workingnotes"
}

@InProceedings{clef-checkthat-en:2020,
 author = "Shaar, Shaden and
    Nikolov, Alex and
    Babulkov, Nikolay and
    Alam, Firoj and  
    Barr\'{o}n-Cede{\~n}o, Alberto and
    Elsayed, Tamer and
    Hasanain, Maram and    
    Suwaileh, Reem and
    Haouari, Fatima and
    {Da San Martino}, Giovanni and
    Nakov, Preslav",
 title = "Overview of {CheckThat!} 2020 {E}nglish: Automatic Identification and Verification of Claims in Social Media",
 crossref = "clef2020-workingnotes"
}

@InProceedings{clef-checkthat-Alkhalifa:2020,
 author = "Alkhalifa, Rabab and
		Yoong, Theodore and
		Kochkina, Elena and
		Zubiaga, Arkaitz and
		Liakata, Maria",
 title = "{QMUL-SDS} at {CheckThat!} 2020: {D}etermining {COVID-19} Tweet 
Check-Worthiness Using an Enhanced {CT-BERT} with Numeric Expressions",
 abstract = "This paper describes the QMUL-SDS team's entry for Task 1 of the 
CLEF 2020 CheckThat! shared task, where we determined the check-worthiness of 
tweets about COVID-19 to prioritise tweets for fact-checking. We utilised a BERT 
language model with binary classification and sigmoid for ranking. In 
particular, we used the uncased COVID-Twitter-BERT architecture that had been 
pre-trained on COVID-19 Twitter stream data using two different language 
modelling tasks: whole word-masked modelling and next sentence prediction. The 
model was trained by jointly optimising a binary cross-entropy loss. We 
performed traditional Twitter data preprocessing in order to improve system 
performance: (1) All Twitter account handles, digits, hashtags and hyperlinks 
were removed; (2) A vector look-up was then used for each token from CO-BERT 
model; (3) Each token was thereafter mapped to a unique integer in the corpus’ 
vocabulary, done using two tokenisers which performed differently in different 
cases; (4) Padding was used to equalise the lengths of the input sequences in a 
batch, i.e. we increase the length of some sequences by adding tokens. We 
attempted to reduce the padding by letting our model decide the padding length 
based on the given batch and its longest sequence, reducing any unnecessary 
overhead carried by the model. We ranked fourth in the task.",
 crossref = "clef2020-workingnotes"
}



@InProceedings{clef-checkthat-Bouziane:2020,
 author = "Bouziane, Mostafa and
        Perrin, Hugo and
        Cluzeau, Aur\`elien and
        Mardas, Julien and
        Sadeq, Amine",
 title = "{Buster.AI} at {CheckThat!} 2020: {I}nsights and recommendations to improve Fact-Checking.",
 abstract = "As part of the CheckThat! 2020 Task 2, we investigated sentence similarity using transformer models. In Task 2, the goal was to effectively rank claims based on their relevancy compared to an input tweet. While setting our baseline on sentence similarity for Fact-Checking, we gathered insights we felt compelled to share in this paper. We learned how multimodal data utilization could foster significant uplifts in model performance. We also gained knowledge on which hybrid training and strong sampling worked best for Fact-Checking applications, and wanted to share our interpretation of the results we got. Finally, we want to explain our recommendations on data augmentations. All of the above allowed us to set our baseline in Fact-Checking in the CLEF Checkthat! 2020 Task 2 competition.",
 crossref = "clef2020-workingnotes"
}

@InProceedings{clef-checkthat-cheema:2020,
 author = "Cheema, Gullal S. and
		Hakimov, Sherzod and
		Ewerth, Ralph",
 title = "Check\_square at {CheckThat!} 2020: {C}laim Detection in Social Media via Fusion of Transformer and Syntactic Features",
 abstract = "In this paper, we focus on solving two problems in the fact-check ecosystem, claim check-worthiness prediction and claim retrieval. For the first problem, we explore the fusion of syntactic features and deep transformer Bidirectional Encoder Representations from Transformers (BERT) embeddings, to classify check-worthiness of a tweet, whether it includes a claim or not. We use Part-of-speech (POS) tags, named entities, and dependency relations as syntactic features and a combination of hidden layers in BERT to compute tweet embedding, and concatenate them to get a large feature embedding. We then reduce the feature size by applying PCA and train an SVM classifier for binary classification of tweets. We conduct a detailed analysis of syntactic feature combinations, word2vec embeddings and BERT hidden layer combinations to find the best performing model. For the second problem, we explore the pre-trained embeddings from a Siamese network transformer model (sentence transformers) specifically trained for semantic textual similarity and perform KD-search to retrieve claims. We further fine-tune these models using triplets with a triplet loss and conduct detailed experiments with different backbone networks.",
 crossref = "clef2020-workingnotes"
}


@InProceedings{clef-checkthat-Kartal:2020,
 author = "Kartal, Yavuz Selim and
		Kutlu, Mucahid",
 title = "{TOBB ETU at CheckThat!} 2020: Prioritizing {E}nglish and {A}rabic Claims Based on Check-Worthiness",
 abstract = "Today’s one of the most popular information resource is the social media and any information as well as misinformation can reach out to thousands of users in a short time. Therefore, automated systems that can prioritize claims based on their check-worthiness have a big role to prevent spreading of misinformation. In this paper, we propose three different models for CLEF Check That! Lab. In all our models, we use logistic regression. The first one uses BERT and word embeddings together. The second model is a hybrid combination of BERT and the first model such that we use only fine-tuned BERT for the first 15 claims. For the others, we use the first model. The last model is a modification of the first model with additional features which are pos tags, domain-specific controversial topics and a handcrafted word list. For the Arabic task, we use AraBert as our Bert model.  We use the first and second models for Task 1 Arabic and all models for Task 1 English and Task 5.
In the official evaluation of primary submissions, our primary models a) ranked 3rd in Task 1 Arabic based on P@30 and shared the 1st rank with another group on P@5,  b) ranked 4th in Task 1 English based on MAP and shared the 1st rank with 5 other groups on RR, P@1, P@3 and P@5, and c) ranked 3rd in Task 5 based on MAP.",
 crossref = "clef2020-workingnotes"
}

@InProceedings{clef-checkthat-Martinez-Rico:2020,
 author = "Martinez-Rico, {Juan R.} and
		Araujo, Lourdes and
		Martinez-Romo, Juan",
 title = "{NLP\&IR@UNED at CheckThat!} 2020: {A} Preliminary Approach for 
Check-Worthiness and Claim Retrieval Tasks using Neural Networks and Graphs",
 abstract = "Check-Worthiness and Claim Retrieval are two of the first tasks to 
be performed on the Fake News detection pipeline. In this article we present our 
approach to these tasks presented in the 2020 edition of the CheckThat! Labs. In 
the Task 1, Tweet Check-Worthiness English, we propose a Bi-LSTM model with 
Glove Twitter embeddings where the number of inputs has been increased with a 
graph generated from the additional information provided for each tweet. In Task 
1 Arabic we have followed a similar approach but using a FFNN model with Arabic 
embeddings. For the task 5, Debate Check-Worthiness, we propose a naive Bi-LSTM 
model with Glove embeddings. Finally our aproach to the Task 2, Claim Retrieval, 
is based in a FFNN model with features such as cosine similarity over USE 
embeddings of tweet and claim, and other linguistic features extracted from both 
elements.",
 crossref = "clef2020-workingnotes"
}

@InProceedings{clef-checkthat-McDonald:2020,
 author = "McDonald, Thomas and
		Dong, ZiQing and
		Zhang, Yingji and
		Hampson, Rebekah and
		Young, James and
		Cao, Qianyu and 
		Leidner, Jochen and
        Stevenson, Mark",
 title = "The {U}niversity of {S}heffield at {CheckThat!} 2020: {C}laim 
		Identification and Verification on {T}witter",
 abstract = "The spread of misinformation online has been gathering pace in  
recent years, and whilst claim verification is an active area of research, the 
COVID-19 pandemic has presented a unique challenge due to the large amount of 
inaccurate information being shared on social media platforms. This paper 
describes our entries to Tasks 1 and 2 of the CLEF 2020 CheckThat! lab, which 
focus on the problems of determining check-worthiness and verification of claims 
found in tweets related to COVID-19. Our best performing approach for Task 1 
employed TF-IDF term weightings and a Random Forest model, ranking 17th out of 
27 systems. For Task 2, our best system involved the use of TF-IDF term 
weightings with a BM25 similarity score and a Support Vector Classifier scoring 
model, ranking 13th out of 22 systems.",
 crossref = "clef2020-workingnotes"
}

@InProceedings{clef-checkthat-Nikolov:2020,
 author = "Nikolov, Alex and {Da San Martino}, Giovanni and Koychev, Ivan and Nakov, Preslav",
 title = "{Team\_Alex at CheckThat!} 2020: Identifying check-worthy tweets with transformer models",
 crossref = "clef2020-workingnotes"
}


@InProceedings{clef-checkthat-Passaro:2020,
 author = "Passaro, {Lucia C.} and
		Bondielli, Alessandro and
		Lenci, Alessandro and
		Marcelloni, Francesco",
title = "{UNIPI-NLE} at {CheckThat!} 2020: {A}pproaching Fact Checking from a  
Sentence Similarity Perspective Through the Lens of Transformers",
abstract = "This paper describes a Fact Checking system based on a combination 
of Information Extraction and Deep Learning strategies to associate a tweet 
with the corresponding claim. The system has been built starting from a 
pre-trained Sentence-BERT model on which two cascade fine-tuning steps have been 
applied. The first step is a sentence similarity task aimed at predicting the 
cosine similarity between a tweet and a claim. Sentence-BERT was used to fine 
tune the model on this task by building a training set in which positive 
examples, consisting of gold tweet-claim pairs, were associated with a maximum 
cosine similarity. Negative examples were instead randomly selected from a list 
of candidate pairs with a non empty overlap in terms of metadata (named entities 
and keywords). Such examples were associated with the original cosine similarity 
between the tweet and claim, lowered by applying a penalty function. The second 
step consists in a binary classification task aimed at deciding whether a 
tweet-claim pair is a correct match or not. The model fine-tuned in the first 
step was enriched with a classifier head on top. Positive and negative examples 
were selected as above to construct the training set. The final ranking produced 
by the system is the predicted probability of the pair labelled as correct. 
Overall, the system reached a 0.91 MAP@5 on the test set.",
crossref = "clef2020-workingnotes"
}


@InProceedings{clef-checkthat-Thuma:2020,
 author   = "Thuma, Edwin and
		Motlogelwa, Nkwebi Peace and
		Leburu-Dingalo, Tebo and
		Mudongo, Monkgogi",
 title    = "{UB\_ET} at {CheckThat!} 2020: {E}xploring Ad hoc Retrieval Approaches in Verified Claims Retrieval",
 abstract = "In this paper, we explore three different ad hoc retrieval approaches to rank verified claims, 
 so that those that verify the input claim are ranked on top. In particular, we deploy DPH Divergence from Randomness (DFR) term weighting model to rank the verified claims.
 In addition, we deploy the Sequential Dependence (SD) variant of the Markov Random Fields (MRF) for term dependence to re-rank documents (verified claims) that have query terms (input claim) in close proximity.
 Moreover, we deploy LambdaMART, which is a learning to rank algorithm that use machine learning techniques to learn an appropriate combination of features into an effective 
ranking model.",
 crossref = "clef2020-workingnotes"
}

@InProceedings{clef-checkthat-Hasanain:2020,
 author = "Hasanain, Maram and
		Elsayed, Tamer",
 title = "big{IR} at {CheckThat!} 2020: {M}ultilingual {BERT} for Ranking {A}rabic Tweets by Check-worthiness",
 abstract = "In this work we use Multilingual bERT pre-trained language model for ranking tweets by check-worthiness.",
 crossref = "clef2020-workingnotes"
}


@InProceedings{clef-checkthat-Touahri:2020,
 author   = "Touahri, Ibtissam and
		Mazroui, Azzeddine",
 title    = "{EvolutionTeam} at {CheckThat!} 2020: {I}ntegration of linguistic and sentimental features in a fake news detection approach",
 crossref = "clef2020-workingnotes"
}

@InProceedings{clef-checkthat-Hussein:2020,
 author = "Hussein, Ahmad and
		Hussein, Abdulkarim and
		Ghneim, Nada and
		Joukhadar, Ammar",
 title = "{DamascusTeam} at {CheckThat!} 2020: {C}heck Worthiness on {T}witter with Hybrid {CNN} and {RNN} Models",
 abstract = "In recent years, online social networks like Twitter, Facebook, Instagram, and others have revolutionized interpersonal communication and it becomes an important platform to share information about current events. Consequently, the research on the informativeness of posts is becoming more important than ever before. In this paper, we present our approach to analyze the informativeness of Arabic information on Twitter. We used a hybrid system of convolutional neural networks and long-short term recurrent neural network models. To train the classification model, in addition to the dataset of 1500 tweets provided from CLEF 2020, we annotated for a data set of 5000 Arabic tweets -corresponding to 4 high impact news events of 2020 around the world. Results show that we can extract the informativeness of tweets with high effectiveness.",
 crossref = "clef2020-workingnotes"
}

@InProceedings{clef-checkthat-williams:2020,
 author = "Williams, Evan and
		Rodrigues, Paul and
		Novak, Valerie",
 title = "Accenture at {CheckThat! 2020: I}f you say so: Post-hoc fact-checking of claims using transformer-based models",
 abstract = "The Accenture team will describe experiments in using transformer fine-tuning to automatically fact-check tweets in English and Arabic.
We fine-tuned the English training data with the RoBERTa base model which was created and open-sourced by Liu et al \cite{roberta}. The base-roberta model was pretrained on 160GB of text extracted from BookCorpus, English Wikipedia, CC-News, OpenWebText, and Stories. To help prevent overfitting, we added an extra mean pooling and dropout layer to the model.
We fine-tuned the Arabic training data with 3 different pre-trained Arabic BERT models- two of which were not trained on stemmed tokens. We used two BERT bases which were pretrained and made open source by Wissam Antoun, Fady Baly, and Hazem Hajj at the American University of Beiruit \cite{aubmindlabs}. The Aubmindlabs Arabert was pretrained on Arabic Articles manually scraped by researchers along with two open source corpora: (1) the 1.5 billion word Arabic Corpus, which contains more than 5 million news articles from ten major news sources. and (2) OSIAN: the Open Source International Arabic News Corpus, which includes more than 3.5 million articles from 31  news sources \cite{aubmindlabs}
In order to improve label balance in the Arabic corpus, and to improve lexical diversity, we used machine translation as an external data source to upsample the positive class of the Arabic training data.  We took the Arabic text, and used Amazon Translate to translate this into English and then back to Arabic.  These translated tweets served as additional training data.
While metadata was provided for the Arabic and English tweets, this approach utilized only the language content.",
 crossref = "clef2020-workingnotes"
}


@proceedings{CLEF_LNCS:20,
 editor =  "Arampatzis, Avi and
    Kanoulas, Evangelos and 
    Tsikrika, Theodora and 
    Vrochidis, Stefanos and 
    Joho, Hideo and 
    Lioma, Christina and 
    Eickhoff, Carsten and
    Névéol, Aurélie and 
    Cappellato, Linda and 
    Ferro, Nicola ",
 title = "{Experimental {IR} Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Eleventh International Conference of the {CLEF} Association 
({CLEF} 2020)}",
 series    = "LNCS (12260)",
 publisher = "Springer",
 year = 2020 
}


@proceedings{clef2020-workingnotes,
 editor = "Cappellato, Linda 
    and Eickhoff, Carsten 
    and Ferro, Nicola and
    Névéol, Aurélie",
    title = "CLEF 2020 Working Notes",
    series    = "{CEUR} Workshop Proceedings",
    NOpublisher = "CEUR-WS.org",
    issn= "1613-0073",
    year = 2020,
    NOaddress = {Thessaloniki, Greece},
}

@inproceedings{antoun2020arabert,
    title = "{A}ra{BERT}: Transformer-based Model for {A}rabic Language Understanding",
    author = "Antoun, Wissam  and
      Baly, Fady  and
      Hajj, Hazem",
    booktitle = "Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools",
    series = {OSAC~'20},
    NOmonth = may,
    year = "2020",
    address = "Marseille, France",
    NOpublisher = "European Language Resource Association",
    NOurl = "https://www.aclweb.org/anthology/2020.osact-1.2",
    pages = "9--15",
    abstract = "The Arabic language is a morphologically rich language with relatively few resources and a less explored syntax compared to English. Given these limitations, Arabic Natural Language Processing (NLP) tasks like Sentiment Analysis (SA), Named Entity Recognition (NER), and Question Answering (QA), have proven to be very challenging to tackle. Recently, with the surge of transformers based models, language-specific BERT based models have proven to be very efficient at language understanding, provided they are pre-trained on a very large corpus. Such models were able to set new standards and achieve state-of-the-art results for most NLP tasks. In this paper, we pre-trained BERT specifically for the Arabic language in the pursuit of achieving the same success that BERT did for the English language. The performance of AraBERT is compared to multilingual BERT from Google and other state-of-the-art approaches. The results showed that the newly developed AraBERT achieved state-of-the-art performance on most tested Arabic NLP tasks. The pretrained araBERT models are publicly available on https://github.com/aub-mind/araBERT hoping to encourage research and applications for Arabic NLP.",
    language = "English",
    ISBN = "979-10-95546-51-1",
}
@inproceedings{devlin2019bert,
  title={{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  series = {NAACL-HLT~'19},
  address = {Minneapolis, Minnesota, USA},
  pages={4171--4186},
  year={2019}
 }


@inproceedings{shahifakecovid,
  title={Fake{C}ovid -- A Multilingual Cross-domain Fact Check News Dataset for {COVID-19}},
  author={Shahi, Gautam Kishore and Nandini, Durgesh},
  booktitle={Workshop Proceedings of the 14th International {AAAI} {C}onference on {W}eb and {S}ocial {M}edia},
  year = {2020},
  Ourl = {http://workshop-proceedings.icwsm.org/pdf/2020_14.pdf}
}


@article{shahi2020exploratory,
  title={An Exploratory Study of {COVID-19} Misinformation on {Twitter}},
  author={Shahi, Gautam Kishore and Dirkson, Anne and Majchrzak, Tim A},
  journal={arXiv preprint arXiv:2005.05710},
  year={2020}
}

@article{shahi2020amused,
  title={{AMUSED}: An Annotation Framework of Multi-modal Social Media Data},
  author={Shahi, Gautam Kishore},
  journal={arXiv:2010.00502},
  year={2020}
}

@article{oshikawa2018survey,
  title={A survey on natural language processing for fake news detection},
  author={Oshikawa, Ray and Qian, Jing and Wang, William Yang},
  journal={arXiv preprint arXiv:1811.00770},
  year={2018}
}

@inproceedings{oshikawa-etal-2020-survey,
    title = "A Survey on Natural Language Processing for Fake News Detection",
    author = "Oshikawa, Ray  and
      Qian, Jing  and
      Wang, William Yang",
    booktitle = "Proceedings of the 12th Language Resources and Evaluation Conference",
    year = "2020",
    series = {LREC~'20},
    pages = "6086--6093",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@article{li2012truth,
 author = {Li, Xian and Dong, Xin Luna and Lyons, Kenneth and Meng, Weiyi and Srivastava, Divesh},
 year = {2012},
 title = {Truth finding on the deep web},
 pages = {97--108},
 volume = {6},
 number = {2},
 issn = {2150-8097},
 journal = {Proceedings of the VLDB Endowment},
 doi = {10.14778/2535568.2448943}
}

@inproceedings{li2011t,
 author = {Li, Xian and Meng, Weiyi and Yu, Clement},
 title = {T-verifier: Verifying truthfulness of fact statements},
 pages = {63--74},
 publisher = {IEEE},
 isbn = {978-1-4244-8959-6},
 booktitle = {Proceedings of the 2011 IEEE 27th International Conference on Data Engineering},
 year = {2011},
 address = {Piscataway, NJ}
}

@article{li2016survey,
  title={A survey on truth discovery},
  author={Li, Yaliang and Gao, Jing and Meng, Chuishi and Li, Qi and Su, Lu and Zhao, Bo and Fan, Wei and Han, Jiawei},
  journal={ACM Sigkdd Explorations Newsletter},
  volume={17},
  number={2},
  pages={1--16},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@InProceedings{CheckThat:ECIR:2020,
author="Barr{\'o}n-Cede{\~{n}}o, Alberto
and Elsayed, Tamer
and Nakov, Preslav
and Da San Martino, Giovanni
and Hasanain, Maram
and Suwaileh, Reem
and Haouari, Fatima",
NOeditor="Jose, Joemon M.
and Yilmaz, Emine
and Magalh{\~a}es, Jo{\~a}o
and Castells, Pablo
and Ferro, Nicola
and Silva, M{\'a}rio J.
and Martins, Fl{\'a}vio",
title="{CheckThat! at CLEF 2020}: Enabling the Automatic Identification and Verification of Claims in Social Media",
booktitle="Advances in Information Retrieval",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="499--507",
abstract="We describe the third edition of the CheckThat! Lab, which is part of the 2020 Cross-Language Evaluation Forum (CLEF). CheckThat! proposes four complementary tasks and a related task from previous lab editions, offered in English, Arabic, and Spanish. Task 1 asks to predict which tweets in a Twitter stream are worth fact-checking. Task 2 asks to determine whether a claim posted in a tweet can be verified using a set of previously fact-checked claims. Task 3 asks to retrieve text snippets from a given set of Web pages that would be useful for verifying a target tweet's claim. Task 4 asks to predict the veracity of a target tweet's claim using a set of potentially-relevant Web pages. Finally, the lab offers a fifth task that asks to predict the check-worthiness of the claims made in English political debates and speeches. CheckThat! features a full evaluation framework. The evaluation is carried out using mean average precision or precision at rank k for ranking tasks, and F{\$}{\$}{\_}1{\$}{\$} for classification tasks.",
isbn="978-3-030-45442-5"
}
